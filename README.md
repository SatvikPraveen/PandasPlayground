# ğŸ“Š PandasPlayground â€“ A Comprehensive Data Manipulation Project

![Python](https://img.shields.io/badge/python-3.11-blue.svg)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Dockerized](https://img.shields.io/badge/docker-ready-blue.svg)
![Notebooks](https://img.shields.io/badge/notebooks-10-brightgreen.svg)

> Master data manipulation with **pandas** â€” from fundamentals to advanced performance tuning â€” using real-world datasets and modular notebooks.

---

## ğŸ§  Project Purpose

**PandasPlayground** is designed to help aspiring data scientists and analysts master the entire pandas ecosystem through hands-on, progressive, and fully-documented Jupyter notebooks. Each module targets a specific capability â€” from data loading and cleaning to advanced transformations and memory profiling â€” ensuring a complete learning and review reference.

![Preview Dashboard](./assets/project_preview.png)

> ğŸ” Preview: Explore datasets, visualize trends, and profile performance â€” all in one playground!

---

## ğŸ“ Project Structure

```plaintext
PandasPlayground/
â”œâ”€â”€ assets/               # Charts, exports, and visual output images
â”œâ”€â”€ cheatsheets/          # Markdown-based reference sheets (e.g., pandas_cheatsheet.md)
â”œâ”€â”€ data/                 # Raw datasets (CSV, Excel, JSON, Parquet)
â”œâ”€â”€ exports/              # Final output files (CSV, Excel, styled reports)
â”œâ”€â”€ notebooks/            # All 10 learning notebooks (01â€“10)
â”œâ”€â”€ pages/                # Streamlit multipage app (expanded)
â”œâ”€â”€ pandas_env/           # Local virtual environment (âš ï¸ add to .gitignore)
â”œâ”€â”€ scripts/              # Modular reusable utility functions
â”œâ”€â”€ Dockerfile            # Docker support for reproducible environments
â”œâ”€â”€ LICENSE.md
â”œâ”€â”€ README.md             # Youâ€™re here!
â”œâ”€â”€ requirements.txt      # All required dependencies
â””â”€â”€ STREAMLIT_App.py      # Interactive dashboard using Streamlit
```

---

## ğŸ§¾ Datasets Used

This project uses **artificially generated datasets** designed to replicate common real-world scenarios. Each file highlights a unique aspect of data handling and analysis using `pandas`.

| Dataset File                 | Format  | Purpose                                                    |
| ---------------------------- | ------- | ---------------------------------------------------------- |
| `superstore_sales.csv`       | CSV     | Simulated retail sales data for grouping, time series      |
| `weather_data.json`          | JSON    | Unstructured data for parsing, cleaning, and visualization |
| `bank_loans.xlsx`            | Excel   | Tabular data for filtering, EDA, and feature engineering   |
| `bank_loans_multisheet.xlsx` | Excel   | Multi-sheet structure for advanced Excel parsing           |
| `covid_data.parquet`         | Parquet | Efficient columnar data for joins and time-based analysis  |

> ğŸ›  These datasets are **not from public sources** and were created to demonstrate the versatility of `pandas` across different formats and data challenges. You can find them in the [`data/`](./data/) folder.

---

## âœ… Modules and Concepts

| Notebook                             | Concepts                                           |
| ------------------------------------ | -------------------------------------------------- |
| `01_data_loading.ipynb`              | Load data, inspect structure, parse dates          |
| `02_data_cleaning.ipynb`             | Handle missing values, type conversion, string ops |
| `03_aggregation_grouping.ipynb`      | GroupBy, pivot, window functions                   |
| `04_merging_joining.ipynb`           | Merge, concat, index joins                         |
| `05_time_series.ipynb`               | Resample, rolling, timezone handling               |
| `06_advanced_pandas.ipynb`           | .apply(), .map(), method chaining, memory tuning   |
| `07_visualization_with_pandas.ipynb` | Bar, line, box, grouped plots                      |
| `08_final_pipeline.ipynb`            | End-to-end data workflow pipeline                  |
| `09_reporting_exporting.ipynb`       | Export to Excel/CSV/Parquet, styled reports        |
| `10_performance_diagnostics.ipynb`   | Profiling, eval(), categorical, Dask               |

---

## ğŸ“š Learning Outcomes

âœ… Develop fluency with `pandas` core APIs
âœ… Build modular, reusable data pipelines
âœ… Understand performance bottlenecks in large datasets
âœ… Practice version-controlled and containerized data science

---

## ğŸ“¦ Installation

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

### ğŸ³ Run with Docker (Optional)

```bash
# Build image
docker build -t pandasplayground .

# Run container on http://localhost:8899
docker run -pd 8899:8888 -v $(pwd):/app pandasplayground
```

---

## ğŸ’» Using the Project

- ğŸ”„ Want to use this on your own data? Start with `08_final_pipeline.ipynb`
- ğŸ§© Reuse functions from `scripts/` for your own ETL workflows
- ğŸ³ Use `Dockerfile` to run in an isolated, reproducible environment

---

## ğŸ§° Tools & Libraries

- **pandas**
- **numpy**
- **matplotlib**, **seaborn**
- **Jupyter**, **JupyterLab**
- **openpyxl**, **pyarrow**
- **memory_profiler**, **psutil**
- **Streamlit** (for interactive dashboards)

---

## ğŸ”— Related Projects

- ğŸ§® [NumPyMasterPro](https://github.com/SatvikPraveen/NumPyMasterPro) â€“ Master NumPy with modular walkthroughs

---

Absolutely! Here's an expanded and professional version of the **How to Contribute or Fork** section to better guide future collaborators:

---

## ğŸ¤ How to Contribute or Fork

Whether you're fixing a bug, suggesting an enhancement, or adding new learning notebooks â€” contributions are welcome and appreciated!

### ğŸ”€ Fork & Clone the Repository

```bash
# Step 1: Fork this repository on GitHub
# Step 2: Clone your fork locally
git clone https://github.com/your-username/PandasPlayground.git
cd PandasPlayground
```

### ğŸŒ± Create a Feature Branch

Always create a new branch for your changes instead of working on `main`:

```bash
git checkout -b feature/your-feature-name
```

### ğŸ›  Make Your Changes

- Add your improvements (e.g., a new notebook, function in `scripts/`, or fixes in `requirements.txt`)
- Follow consistent formatting, naming, and markdown style as used across the project
- Update the README.md or cheatsheets if your change impacts the documentation
- Test your code locally (if it includes logic)

### âœ… Commit and Push

```bash
git add .
git commit -m "âœ¨ Added: Short summary of your feature"
git push origin feature/your-feature-name
```

### ğŸ“© Submit a Pull Request

- Go to your fork on GitHub
- Click **"Compare & pull request"**
- Provide a clear and concise description of your changes
- If applicable, reference any related issue (e.g., `Fixes #12`)
- Wait for review or feedback

---

### ğŸ§ª Contribution Tips

- Keep changes **modular and atomic** â€” one feature or fix per pull request
- Be sure to **sync your fork** with the upstream repository periodically:

  ```bash
  git remote add upstream https://github.com/SatvikPraveen/PandasPlayground.git
  git pull upstream main
  ```

- If your feature involves code, prefer writing **reusable functions** in `scripts/` and importing them in your notebooks

---

### ğŸ™ Thank You

Every contribution, no matter how small, helps improve this resource for the entire data science community.
Letâ€™s build this playground together! ğŸ‰

---

## ğŸ“œ License

This project is licensed under the MIT License. See [LICENSE](./LICENSE) for more info.

---

## ğŸ™‹â€â™‚ï¸ Author

Built with ğŸ’» and â˜• by [Satvik Praveen](https://github.com/SatvikPraveen)
Drop a â­ if you find this project helpful!
